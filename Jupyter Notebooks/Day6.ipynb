{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502e0a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProject Overview[Ice Cream Sales Seasonal Performance Assessment]:\\nThis project seeks to investigate seasonal sales patterns through comprehensive data analysis. \\n\\nGoals:To understand how temperature variations and unique transaction characteristics impact ice cream sales volume\\n    :To perform detailed data cleaning and exploratory analysis to uncover meaningful insights about seasonal sales performance.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Project Overview[Ice Cream Sales Seasonal Performance Assessment]:\n",
    "This project seeks to investigate seasonal sales patterns through comprehensive data analysis. \n",
    "\n",
    "Goals:To understand how temperature variations and unique transaction characteristics impact ice cream sales volume\n",
    "    :To perform detailed data cleaning and exploratory analysis to uncover meaningful insights about seasonal sales performance.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab9acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda0fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_date  temperature                product_name  sales_volume  \\\n",
      "0    7/5/2024         62.0               Cherry Garcia            23   \n",
      "1   8/15/2024         64.0               Chunky Monkey            26   \n",
      "2   9/25/2024         66.0                  Phish Food            29   \n",
      "3   10/5/2024         68.0             Americone Dream            32   \n",
      "4  11/15/2024         70.0     Chocolate Fudge Brownie            35   \n",
      "5  12/25/2024         72.0                  Half Baked            38   \n",
      "6    1/5/2025         74.0  New York Super Fudge Chunk            41   \n",
      "7   2/15/2025         76.0               Cherry Garcia            44   \n",
      "8   3/25/2025         78.0               Chunky Monkey            47   \n",
      "9    4/5/2025         80.0                  Phish Food            50   \n",
      "\n",
      "  transaction_id  \n",
      "0         TX0001  \n",
      "1         TX0002  \n",
      "2         TX0003  \n",
      "3         TX0004  \n",
      "4         TX0005  \n",
      "5         TX0006  \n",
      "6         TX0007  \n",
      "7         TX0008  \n",
      "8         TX0009  \n",
      "9         TX0010  \n",
      "['sale_date', 'temperature', 'product_name', 'sales_volume', 'transaction_id']\n",
      "Number of rows and columns is: (59, 5)\n"
     ]
    }
   ],
   "source": [
    "# Getting the Dataset\n",
    "ice_cream_sales_data = pd.read_csv(r'D:\\Data Journey\\Python-Summer-Party\\DataSets\\ice_cream_sales_data.csv')\n",
    "\n",
    "# Display the first few rows to understand the data\n",
    "print(ice_cream_sales_data .head(10))  # Shows the first 5 rows with columns\n",
    "print(list(ice_cream_sales_data .columns))\n",
    "print('Number of rows and columns is:', ice_cream_sales_data .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cf0c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated sales transactions: 0\n",
      "Dataset shape after removing duplicates: (59, 5)\n"
     ]
    }
   ],
   "source": [
    "# Question One:\n",
    "# Data Cleaning to remove duplicate sales transactions from the dataset to ensure accurate analysis of seasonal patterns\n",
    "# 0. Check for duplicate transaction IDs\n",
    "duplicated_sales_transactions = ice_cream_sales_data['transaction_id'].duplicated().sum()\n",
    "print(f'Number of duplicated sales transactions: {duplicated_sales_transactions}')\n",
    "\n",
    "# 1. Drop duplicates based on 'transaction_id' (keeping the first occurrence)\n",
    "ice_cream_sales_data = ice_cream_sales_data.drop_duplicates(subset='transaction_id', keep='first').reset_index(drop=True)\n",
    "print(f\"Dataset shape after removing duplicates: {ice_cream_sales_data.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Arewadatascience)",
   "language": "python",
   "name": "arewadatascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
